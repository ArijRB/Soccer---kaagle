{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction des resultats des match avec Arbre de Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "# Permet d'afficher les figures directement dans le notebook:\n",
    "%matplotlib inline\n",
    "%run ./classes_utiles_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(\"./train_data.npy\")\n",
    "train_labels = np.load(\"./train_labels.npy\")\n",
    "test_data = np.load(\"./test_data.npy\")\n",
    "test_labels = np.load(\"./test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = LabeledSet(len(train_data[0]))\n",
    "for i in range(len(train_data)):\n",
    "    train_set.addExample(train_data[i], [train_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = LabeledSet(len(test_data[0]))\n",
    "for i in range(len(test_data)):\n",
    "    test_set.addExample(test_data[i], [test_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classe_majoritaire(Lset):\n",
    "    \n",
    "    classes = [-1, +1]\n",
    "    frequences = [0, 0]\n",
    "    \n",
    "    for i in range(Lset.size()):\n",
    "        frequences[classes.index(Lset.getY(i))] += 1\n",
    "    \n",
    "    if(frequences[0] == frequences[1]):\n",
    "        return +1\n",
    "    elif(frequences[0] > frequences[1]):\n",
    "        return classes[0]\n",
    "    else:\n",
    "        return classes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shannon(probas):\n",
    "    k = len(probas)\n",
    "    total = 0.0\n",
    "    for i in probas:\n",
    "        if(i == 0):\n",
    "            continue\n",
    "            \n",
    "        total = total + (i * (np.log(i) / np.log(k)))\n",
    "        \n",
    "    return np.abs(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropie(Lset):\n",
    "    n = Lset.size()\n",
    "    proba1 = 0\n",
    "    proba_1 = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        if(Lset.getY(i) == 1):\n",
    "            proba1 = proba1 + 1\n",
    "        else:\n",
    "            proba_1 = proba_1 + 1\n",
    "            \n",
    "    probas = [proba1*1.0/n, proba_1*1.0/n]\n",
    "    return shannon(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretise(LSet, col):\n",
    "    \"\"\" LabelledSet * int -> tuple[float, float]\n",
    "        col est le numéro de colonne sur X à discrétiser\n",
    "        rend la valeur de coupure qui minimise l'entropie ainsi que son entropie.\n",
    "    \"\"\"\n",
    "    # initialisation:\n",
    "    min_entropie = 1.1  # on met à une valeur max car on veut minimiser\n",
    "    min_seuil = 0.0     \n",
    "    # trie des valeurs:\n",
    "    ind= np.argsort(LSet.x,axis=0)\n",
    "    \n",
    "    # calcul des distributions des classes pour E1 et E2:\n",
    "    inf_plus  = 0               # nombre de +1 dans E1\n",
    "    inf_moins = 0               # nombre de -1 dans E1\n",
    "    sup_plus  = 0               # nombre de +1 dans E2\n",
    "    sup_moins = 0               # nombre de -1 dans E2       \n",
    "    # remarque: au départ on considère que E1 est vide et donc E2 correspond à E. \n",
    "    # Ainsi inf_plus et inf_moins valent 0. Il reste à calculer sup_plus et sup_moins \n",
    "    # dans E.\n",
    "    for j in range(0,LSet.size()):\n",
    "        if (LSet.getY(j)[0] == -1):\n",
    "            sup_moins += 1\n",
    "        else:\n",
    "            sup_plus += 1\n",
    "    nb_total = (sup_plus + sup_moins) # nombre d'exemples total dans E\n",
    "    \n",
    "    # parcours pour trouver le meilleur seuil:\n",
    "    for i in range(len(LSet.x)-1):\n",
    "        v_ind_i = ind[i]   # vecteur d'indices\n",
    "        courant = LSet.getX(v_ind_i[col])[col]\n",
    "        lookahead = LSet.getX(ind[i+1][col])[col]\n",
    "        val_seuil = (courant + lookahead) / 2.0;\n",
    "        # M-A-J de la distrib. des classes:\n",
    "        # pour réduire les traitements: on retire un exemple de E2 et on le place\n",
    "        # dans E1, c'est ainsi que l'on déplace donc le seuil de coupure.\n",
    "        if LSet.getY(ind[i][col])[0] == -1:\n",
    "            inf_moins += 1\n",
    "            sup_moins -= 1\n",
    "        else:\n",
    "            inf_plus += 1\n",
    "            sup_plus -= 1\n",
    "        # calcul de la distribution des classes de chaque côté du seuil:\n",
    "        nb_inf = (inf_moins + inf_plus)*1.0     # rem: on en fait un float pour éviter\n",
    "        nb_sup = (sup_moins + sup_plus)*1.0     # que ce soit une division entière.\n",
    "        # calcul de l'entropie de la coupure\n",
    "        val_entropie_inf = shannon([inf_moins / nb_inf, inf_plus  / nb_inf])\n",
    "        val_entropie_sup = shannon([sup_moins / nb_sup, sup_plus  / nb_sup])\n",
    "        val_entropie = (nb_inf / nb_total) * val_entropie_inf + (nb_sup / nb_total) * val_entropie_sup\n",
    "        # si cette coupure minimise l'entropie, on mémorise ce seuil et son entropie:\n",
    "        if (min_entropie > val_entropie):\n",
    "            min_entropie = val_entropie\n",
    "            min_seuil = val_seuil\n",
    "    return (min_seuil, min_entropie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divise(Lset, att, seuil):\n",
    "    the_set1 = LabeledSet(Lset.input_dimension)\n",
    "    the_set2 = LabeledSet(Lset.input_dimension)\n",
    "    \n",
    "    for i in range(Lset.size()):\n",
    "        if(Lset.getX(i)[att] <= seuil):\n",
    "            the_set1.addExample(Lset.getX(i), Lset.getY(i))\n",
    "        else:\n",
    "            the_set2.addExample(Lset.getX(i), Lset.getY(i))\n",
    "            \n",
    "    return the_set1,the_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "\n",
    "class ArbreBinaire:\n",
    "    def __init__(self):\n",
    "        self.attribut = None   # numéro de l'attribut\n",
    "        self.seuil = None\n",
    "        self.inferieur = None # ArbreBinaire Gauche (valeurs <= au seuil)\n",
    "        self.superieur = None # ArbreBinaire Gauche (valeurs > au seuil)\n",
    "        self.classe = None # Classe si c'est une feuille: -1 ou +1\n",
    "        \n",
    "    def est_feuille(self):\n",
    "        \"\"\" rend True si l'arbre est une feuille \"\"\"\n",
    "        return self.seuil == None\n",
    "    \n",
    "    def ajoute_fils(self,ABinf,ABsup,att,seuil):\n",
    "        \"\"\" ABinf, ABsup: 2 arbres binaires\n",
    "            att: numéro d'attribut\n",
    "            seuil: valeur de seuil\n",
    "        \"\"\"\n",
    "        self.attribut = att\n",
    "        self.seuil = seuil\n",
    "        self.inferieur = ABinf\n",
    "        self.superieur = ABsup\n",
    "    \n",
    "    def ajoute_feuille(self,classe):\n",
    "        \"\"\" classe: -1 ou + 1\n",
    "        \"\"\"\n",
    "        self.classe = classe\n",
    "        \n",
    "    def classifie(self,exemple):\n",
    "        \"\"\" exemple : numpy.array\n",
    "            rend la classe de l'exemple: +1 ou -1\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            return self.classe\n",
    "        if exemple[self.attribut] <= self.seuil:\n",
    "            return self.inferieur.classifie(exemple)\n",
    "        return self.superieur.classifie(exemple)\n",
    "    \n",
    "    def to_graph(self, g, prefixe='A'):\n",
    "        \"\"\" construit une représentation de l'arbre pour pouvoir\n",
    "            l'afficher\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            g.node(prefixe,str(self.classe),shape='box')\n",
    "        else:\n",
    "            g.node(prefixe, str(self.attribut))\n",
    "            self.inferieur.to_graph(g,prefixe+\"g\")\n",
    "            self.superieur.to_graph(g,prefixe+\"d\")\n",
    "            g.edge(prefixe,prefixe+\"g\", '<='+ str(self.seuil))\n",
    "            g.edge(prefixe,prefixe+\"d\", '>'+ str(self.seuil))\n",
    "        \n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construit_AD(Lset, epsilon):\n",
    "    entr = entropie(Lset)\n",
    "    if(entr <= epsilon):\n",
    "        c_maj = classe_majoritaire(Lset)\n",
    "        abr = ArbreBinaire()\n",
    "        abr.ajoute_feuille(c_maj)\n",
    "        return abr\n",
    "    else:\n",
    "        l_seuil = []\n",
    "        l_entropie = []\n",
    "        #On calcule l'entropie pour chaque attribut\n",
    "        for i in range(Lset.input_dimension):\n",
    "            seuil,entr = discretise(Lset, i)\n",
    "            l_seuil.append(seuil)\n",
    "            l_entropie.append(entr)\n",
    "        \n",
    "        #on prend l'attribut qui minimise cette entropie\n",
    "        ind_min = np.argmin(l_entropie)\n",
    "        seuil = l_seuil[ind_min]\n",
    "        \n",
    "        set_gauche,set_droite = divise(Lset, ind_min, seuil)\n",
    "        \n",
    "        abr_gauche = construit_AD(set_gauche, epsilon)\n",
    "        abr_droite = construit_AD(set_droite, epsilon)\n",
    "        \n",
    "        abr = ArbreBinaire()\n",
    "        abr.ajoute_fils(abr_gauche, abr_droite, ind_min, seuil)\n",
    "        \n",
    "        return abr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ArbreDecision(Classifier):\n",
    "    # Constructeur\n",
    "    def __init__(self,epsilon):\n",
    "        # valeur seuil d'entropie pour arrêter la construction\n",
    "        self.epsilon= epsilon\n",
    "        self.racine = None\n",
    "    \n",
    "    # Permet de calculer la prediction sur x => renvoie un score\n",
    "    def predict(self,x):\n",
    "        # classification de l'exemple x avec l'arbre de décision\n",
    "        # on rend 0 (classe -1) ou 1 (classe 1)\n",
    "        classe = self.racine.classifie(x)\n",
    "        if (classe == 1):\n",
    "            return(1)\n",
    "        else:\n",
    "            return(-1)\n",
    "    \n",
    "    # Permet d'entrainer le modele sur un ensemble de données\n",
    "    def train(self,set):\n",
    "        # construction de l'arbre de décision \n",
    "        self.set=set\n",
    "        self.racine = construit_AD(set,self.epsilon)\n",
    "\n",
    "    # Permet d'afficher l'arbre\n",
    "    def plot(self):\n",
    "        gtree = gv.Digraph(format='png')\n",
    "        return self.racine.to_graph(gtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ma fonction d'arbre de décision fonctionne pas avec un epsilon petit, cela est du au fait que la pile des appels récursifs est limité et qu'on arrive à un moment avec beaucoup d'appels dans la pile ce qui bloque le programme. Pour cela, je vais tester avec le code de l'arbre décision déjà fourni dans la librairie standard sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.26231106777181\n"
     ]
    }
   ],
   "source": [
    "total_bon = 0\n",
    "arr = clf.predict(test_data)\n",
    "for i in range(len(test_data)):\n",
    "    if(arr[i] == test_labels[i]):\n",
    "        total_bon = total_bon + 1\n",
    "print(\"accuracy = \" + str((total_bon*1.0 / l)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
